{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import random \n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "tf.keras.utils.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vahid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "with open('./Data/neg_u_13k.csv') as f:\n",
    "    neg_lines = f.readlines()\n",
    "with open('./Data/neu_u_13k.csv') as f:\n",
    "    neu_lines = f.readlines()\n",
    "with open('./Data/pos_u_13k.csv') as f:\n",
    "    pos_lines = f.readlines()\n",
    "\n",
    "neg_tweets = [ i[2:-2] for i in neg_lines ]\n",
    "neu_tweets = [ i[2:-2] for i in neu_lines ]\n",
    "pos_tweets = [ i[2:-2] for i in pos_lines ]\n",
    "\n",
    "tweets = neg_tweets + neu_tweets + pos_tweets\n",
    "\n",
    "# stemming\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for index, tweet in enumerate(tweets):\n",
    "    \n",
    "    tokens = tweet.split()\n",
    "\n",
    "    stemmed_tweet_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    tweets[index] = ' '.join([ i for i in stemmed_tweet_tokens ]) #if len(i) > 1 and not i.startswith('http') and not i.startswith('@') ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.convert_to_tensor(tweets)\n",
    "\n",
    "labels = tf.convert_to_tensor(np.concatenate([np.zeros(len(neg_tweets)) - 1,\n",
    "                                              np.zeros(len(neu_tweets)) ,\n",
    "                                              np.zeros(len(pos_tweets)) + 1,\n",
    "                                             ]) )\n",
    "labels = tf.keras.utils.to_categorical(labels, 3)  # one-hot encoding the labels\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.shuffle(len(dataset), seed=0).batch(32)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15 \n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "test_size = int(test_ratio * len(dataset))\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size).take(val_size)\n",
    "test_dataset = dataset.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RNN -> 93% Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t Training Accuracy (last-batch): 91.83 \t Validation Accuracy (epoch): 93.6\n",
      "epoch: 2 \t Training Accuracy (last-batch): 92.19 \t Validation Accuracy (epoch): 93.7\n",
      "epoch: 3 \t Training Accuracy (last-batch): 92.03 \t Validation Accuracy (epoch): 93.36\n",
      "epoch: 4 \t Training Accuracy (last-batch): 91.94 \t Validation Accuracy (epoch): 93.99\n",
      "epoch: 5 \t Training Accuracy (last-batch): 92.26 \t Validation Accuracy (epoch): 93.41\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 3000\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_dataset.map(lambda tweets, labels: tweets))\n",
    "# text_vec_layer.get_vocabulary()\n",
    "\n",
    "embed_size = 128\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Custom callback to display accuracy during training\n",
    "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        print(f\"batch: {batch}, Accuracy: {logs['accuracy']*100}\", end='\\r')\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"epoch: {epoch + 1} \\t Training Accuracy (last-batch): {round(logs['accuracy']*100, 2)} \\t Validation Accuracy (epoch): {round(logs['val_accuracy']*100, 2)}\")\n",
    "\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=35, verbose=0, callbacks=[AccuracyCallback()])  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pretrained language model  -> 95% Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow_hub as hub\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"./tfhub_cache\"\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "        trainable=True, dtype=tf.string, input_shape=[]),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=5, verbose=0, callbacks=[AccuracyCallback()])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
